{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Kaggle Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "is_kaggle = \"KAGGLE_WORKING_DIR\" in os.environ or \"/kaggle\" in os.getcwd()\n",
    "print(\"Running on Kaggle:\", is_kaggle)\n",
    "\n",
    "if is_kaggle:\n",
    "    path = Path(\"/kaggle/input/us-patent-phrase-to-phrase-matching\")\n",
    "    ! pip install -q datasets\n",
    "else:\n",
    "    path = Path(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(path/\"train.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A good starting point within any Kaggle competition is to check the what our data consists of. To do this we should:\n",
    "\n",
    "1. Print out the data frame\n",
    "2. Read the [Dataset description](https://www.kaggle.com/competitions/us-patent-phrase-to-phrase-matching/data)\n",
    "3. Call dataframe's `describe()` method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe(include=\"object\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We're going to do a lot with not much unique data. There's a lot of repetition and each entry only has 3-4 words."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we want to create an input column for our NLP model to read that combines categorizes and combines all our text columns in to one string we'll input in to the mode;."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"input\"] = \"TEXT1: \" + df.context + \"; TEXT2: \" + df.target + \"; ANC1: \" + df.anchor\n",
    "df.input.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Machine Learning models operate on numbers not text. We need to convert our input in to numbers. To do this we need to do two things:\n",
    "1. Tokenization: Split each text up in to tokens\n",
    "2. Numericalization: Convert each token in to a number"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transformers use Datasets for storing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import Dataset, DatasetDict\n",
    "ds = Dataset.from_pandas(df)\n",
    "ds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How to tokenize & numericalize text varys between different models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"microsoft/deberta-v3-small\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tokens aren't necessarily words as we need to be able to handle text that isn't made up of words such as URLs and we need to limit the size of our vocabularly so less common words will be split up."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForSequenceClassification,AutoTokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "tokenizer.tokenize(\"This is Declan's tokenizer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenization_func(dataset): return tokenizer(dataset[\"input\"])\n",
    "tokenized_dataset = ds.map(tokenization_func, batched=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This adds a new item to our dataset `input_ids` which converts our text in to numbers that match up with one of our models tokens. This list of tokens is known as the model's vocabulary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "row = tokenized_dataset[0]\n",
    "row[\"input\"], row[\"input_ids\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.convert_ids_to_tokens(54453)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transformers always assume that your labels are within a column named `labels` so we need to rename our score column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_dataset = tokenized_dataset.rename_columns({'score':'labels'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a Validation Set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In practice a making a random split for a validation set is [often a bad practice](https://www.fast.ai/2017/11/13/validation-sets/). \n",
    "\n",
    "Note that for Kaggle competitions we use the training data for our validation set. The test data is for our test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_dict = tokenized_dataset.train_test_split(0.25, seed=42)\n",
    "ds_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.read_csv(path/\"test.csv\")\n",
    "test_df[\"input\"] = \"TEXT1: \" + test_df.context + \"; TEXT2: \" + test_df.target + \"; ANC1: \" + test_df.anchor\n",
    "test_ds = Dataset.from_pandas(test_df).map(tokenization_func, batched=True)\n",
    "test_ds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The batch-size may need adjusting to fit the GPU we choose to use. If a memory crash occurs during training a lower batch size will be required.\n",
    "\n",
    "Learning rate will also require some trial and error, like batch size the larger the value the faster we'll train but a value too large will result in failure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TrainingArguments, Trainer\n",
    "learning_rate = 8e-5\n",
    "epoch_count = 4\n",
    "if is_kaggle:\n",
    "    batch_size = 128\n",
    "    fp16 = True\n",
    "else:\n",
    "    batch_size = 32\n",
    "    fp16 = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The arguments below should work fine in most cases, diving in to them isn't necessary at this stage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = TrainingArguments('outputs', \n",
    "                         learning_rate=learning_rate,\n",
    "                         warmup_ratio=0.1,\n",
    "                         lr_scheduler_type='cosine',\n",
    "                         fp16=fp16,\n",
    "                         evaluation_strategy='epoch',\n",
    "                         per_device_train_batch_size=batch_size,\n",
    "                         per_device_eval_batch_size=batch_size*2,\n",
    "                         num_train_epochs=epoch_count,\n",
    "                         weight_decay=0.01,\n",
    "                         report_to='none')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now create a `Trainer` which combines our model and data together. It will spit out a few warnings we can ignore."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=1)\n",
    "def corr(x,y): return np.corrcoef(x,y)[0][1]\n",
    "def corr_d(eval_pred): return {'pearson': corr(*eval_pred)}\n",
    "\n",
    "trainer = Trainer(model, \n",
    "                  args, \n",
    "                  train_dataset=ds_dict['train'], \n",
    "                  eval_dataset=ds_dict['test'],\n",
    "                  tokenizer=tokenizer,\n",
    "                  compute_metrics=corr_d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
